#!/usr/bin/env python3
"""
æµ‹è¯•æ¨ç†è„šæœ¬
"""

import os
import sys
import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('/root/foodseg')

from model import create_model
from utils import create_colored_mask
from config import *
import albumentations as A
from albumentations.pytorch import ToTensorV2


def test_inference(image_path="image.jpg"):
    """æµ‹è¯•æ¨ç†åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æ¨ç†åŠŸèƒ½")
    print("="*50)
    
    # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return False
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(MODEL_SAVE_DIR, 'best_model.pth')
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_path}")
    model = create_model(NUM_CLASSES, pretrained=False)
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
    print(f"ğŸ–¼ï¸  åŠ è½½å›¾åƒ: {image_path}")
    original_image = cv2.imread(image_path)
    if original_image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ")
        return False
    
    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
    original_shape = original_image.shape
    print(f"åŸå§‹å›¾åƒå½¢çŠ¶: {original_shape}")
    
    # é¢„å¤„ç†
    transform = A.Compose([
        A.Resize(height=IMAGE_SIZE[0], width=IMAGE_SIZE[1]),
        A.Normalize(mean=MEAN, std=STD),
        ToTensorV2()
    ])
    
    transformed = transform(image=original_image)
    input_tensor = transformed['image'].unsqueeze(0).to(device)
    print(f"è¾“å…¥å¼ é‡å½¢çŠ¶: {input_tensor.shape}")
    
    # æ¨ç†
    print("ğŸ” æ‰§è¡Œæ¨ç†...")
    with torch.no_grad():
        outputs = model(input_tensor)
        predictions = outputs['out']
        pred_mask = torch.argmax(predictions, dim=1)
    
    print(f"é¢„æµ‹è¾“å‡ºå½¢çŠ¶: {pred_mask.shape}")
    
    # åå¤„ç†
    pred_mask_np = pred_mask.squeeze(0).cpu().numpy()
    print(f"é¢„æµ‹æ©ç å½¢çŠ¶: {pred_mask_np.shape}")
    
    # è°ƒæ•´åˆ°åŸå§‹å°ºå¯¸
    if pred_mask_np.shape != original_shape[:2]:
        pred_mask_np = cv2.resize(
            pred_mask_np.astype(np.float32),
            (original_shape[1], original_shape[0]),
            interpolation=cv2.INTER_NEAREST
        ).astype(np.uint8)
    
    print(f"è°ƒæ•´åæ©ç å½¢çŠ¶: {pred_mask_np.shape}")
    
    # åˆ›å»ºå½©è‰²æ©ç 
    try:
        colored_mask = create_colored_mask(pred_mask_np, NUM_CLASSES)
        print(f"å½©è‰²æ©ç å½¢çŠ¶: {colored_mask.shape}")
    except Exception as e:
        print(f"âš ï¸  åˆ›å»ºå½©è‰²æ©ç å¤±è´¥: {str(e)}")
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„å½©è‰²æ©ç 
        colored_mask = np.zeros((*pred_mask_np.shape, 3))
        unique_classes = np.unique(pred_mask_np)
        colors = plt.cm.tab20(np.linspace(0, 1, len(unique_classes)))
        for i, class_id in enumerate(unique_classes):
            mask = pred_mask_np == class_id
            colored_mask[mask] = colors[i][:3]
        print(f"ç®€å•å½©è‰²æ©ç å½¢çŠ¶: {colored_mask.shape}")
    
    # æµ‹è¯•å›¾åƒå åŠ 
    print("ğŸ¨ æµ‹è¯•å›¾åƒå åŠ ...")
    try:
        # ç¡®ä¿å°ºå¯¸åŒ¹é…
        if colored_mask.shape[:2] != original_image.shape[:2]:
            colored_mask = cv2.resize(colored_mask, (original_image.shape[1], original_image.shape[0]))
        
        # ç¡®ä¿æ•°æ®ç±»å‹åŒ¹é…
        original_float = original_image.astype(np.float32)
        colored_float = (colored_mask * 255).astype(np.float32)
        
        print(f"å åŠ å‰ - åŸå§‹å›¾åƒ: {original_float.shape}, å½©è‰²æ©ç : {colored_float.shape}")
        
        overlay = cv2.addWeighted(original_float, 0.7, colored_float, 0.3, 0)
        overlay = np.clip(overlay, 0, 255).astype(np.uint8)
        
        print(f"å åŠ åå½¢çŠ¶: {overlay.shape}")
        print("âœ… å›¾åƒå åŠ æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ å›¾åƒå åŠ å¤±è´¥: {str(e)}")
        overlay = original_image
    
    # åˆ†æç»“æœ
    unique_classes = np.unique(pred_mask_np)
    print(f"æ£€æµ‹åˆ°çš„ç±»åˆ«: {unique_classes}")
    
    total_pixels = pred_mask_np.size
    for class_id in unique_classes:
        if class_id == 0:
            continue
        pixels = np.sum(pred_mask_np == class_id)
        percentage = (pixels / total_pixels) * 100
        if percentage > 1.0:
            print(f"ç±»åˆ« {class_id}: {percentage:.2f}% ({pixels:,} åƒç´ )")
    
    # åˆ›å»ºç®€å•å¯è§†åŒ–
    print("ğŸ“Š åˆ›å»ºå¯è§†åŒ–...")
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    axes[0, 0].imshow(original_image)
    axes[0, 0].set_title('åŸå§‹å›¾åƒ')
    axes[0, 0].axis('off')
    
    axes[0, 1].imshow(pred_mask_np, cmap='tab20')
    axes[0, 1].set_title('åˆ†å‰²æ©ç ')
    axes[0, 1].axis('off')
    
    axes[1, 0].imshow(colored_mask)
    axes[1, 0].set_title('å½©è‰²æ©ç ')
    axes[1, 0].axis('off')
    
    axes[1, 1].imshow(overlay)
    axes[1, 1].set_title('å åŠ ç»“æœ')
    axes[1, 1].axis('off')
    
    plt.suptitle('æ¨ç†æµ‹è¯•ç»“æœ')
    plt.tight_layout()
    
    # ä¿å­˜ç»“æœ
    output_path = 'test_inference_result.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    plt.show()
    
    print("âœ… æ¨ç†æµ‹è¯•å®Œæˆ!")
    return True


if __name__ == "__main__":
    if len(sys.argv) > 1:
        image_path = sys.argv[1]
    else:
        image_path = "image.jpg"
    
    success = test_inference(image_path)
    if success:
        print("ğŸ‰ æµ‹è¯•æˆåŠŸ!")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥!")
