"""
LRASPP MobileNetV3-Large è¾“å…¥è§„æ ¼è¯´æ˜å’Œæµ‹è¯•

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº† lraspp_mobilenet_v3_large æ¨¡å‹çš„è¾“å…¥è¦æ±‚å’Œä½¿ç”¨æ–¹æ³•
"""

import torch
import torch.nn.functional as F
from torchvision.models.segmentation import lraspp_mobilenet_v3_large
from torchvision.models.segmentation.lraspp import LRASPP_MobileNet_V3_Large_Weights
import numpy as np

def test_lraspp_inputs():
    """æµ‹è¯• LRASPP æ¨¡å‹çš„å„ç§è¾“å…¥æ ¼å¼"""
    
    print("=" * 60)
    print("LRASPP MobileNetV3-Large è¾“å…¥è§„æ ¼æµ‹è¯•")
    print("=" * 60)
    
    # 1. åˆ›å»ºæ¨¡å‹
    print("1. åˆ›å»ºé¢„è®­ç»ƒæ¨¡å‹...")
    weights = LRASPP_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1
    model = lraspp_mobilenet_v3_large(weights=weights)
    model.eval()
    
    print(f"   âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print(f"   ğŸ“Š åŸå§‹ç±»åˆ«æ•°: {model.classifier.high_classifier.out_channels}")
    
    # 2. è¾“å…¥è§„æ ¼è¯´æ˜
    print("\n2. è¾“å…¥å¼ é‡è§„æ ¼:")
    print("   ğŸ“‹ æ ¼å¼: (batch_size, channels, height, width)")
    print("   ğŸ“‹ é€šé“æ•°: 3 (RGB)")
    print("   ğŸ“‹ æ•°æ®ç±»å‹: torch.float32")
    print("   ğŸ“‹ æ•°å€¼èŒƒå›´: [0, 1] (ç»è¿‡å½’ä¸€åŒ–)")
    print("   ğŸ“‹ æ¨èå°ºå¯¸: å¯å˜ï¼Œä½†å»ºè®® >= 224x224")
    
    # 3. æ ‡å‡†åŒ–å‚æ•°
    print("\n3. é¢„å¤„ç†è¦æ±‚:")
    print("   ğŸ¨ ImageNet æ ‡å‡†åŒ–:")
    print("   ğŸ“Š Mean: [0.485, 0.456, 0.406]")
    print("   ğŸ“Š Std:  [0.229, 0.224, 0.225]")
    
    # 4. æµ‹è¯•ä¸åŒå°ºå¯¸çš„è¾“å…¥
    test_sizes = [
        (224, 224),   # æœ€å°æ¨èå°ºå¯¸
        (256, 256),   # å¸¸ç”¨å°ºå¯¸
        (384, 384),   # ä¸­ç­‰å°ºå¯¸
        (512, 512),   # é¡¹ç›®ä½¿ç”¨å°ºå¯¸
        (640, 480),   # ä¸åŒå®½é«˜æ¯”
        (768, 768),   # å¤§å°ºå¯¸
    ]
    
    print("\n4. æµ‹è¯•ä¸åŒè¾“å…¥å°ºå¯¸:")
    for i, (h, w) in enumerate(test_sizes):
        try:
            # åˆ›å»ºéšæœºè¾“å…¥ (æ ‡å‡†åŒ–åçš„)
            x = torch.randn(1, 3, h, w)  # æ¨¡æ‹Ÿæ ‡å‡†åŒ–åçš„å›¾åƒ
            
            with torch.no_grad():
                output = model(x)
                out_shape = output['out'].shape
                
            print(f"   âœ… {h}x{w}: è¾“å…¥ {x.shape} â†’ è¾“å‡º {out_shape}")
            
        except Exception as e:
            print(f"   âŒ {h}x{w}: é”™è¯¯ - {str(e)}")
    
    # 5. æ‰¹å¤„ç†æµ‹è¯•
    print("\n5. æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°:")
    batch_sizes = [1, 2, 4, 8, 16]
    input_size = (512, 512)
    
    for batch_size in batch_sizes:
        try:
            x = torch.randn(batch_size, 3, *input_size)
            
            with torch.no_grad():
                output = model(x)
                out_shape = output['out'].shape
                
            print(f"   âœ… Batch {batch_size}: è¾“å…¥ {x.shape} â†’ è¾“å‡º {out_shape}")
            
        except Exception as e:
            print(f"   âŒ Batch {batch_size}: é”™è¯¯ - {str(e)}")
    
    # 6. è¾“å‡ºæ ¼å¼è¯´æ˜
    print("\n6. è¾“å‡ºæ ¼å¼:")
    x = torch.randn(1, 3, 512, 512)
    with torch.no_grad():
        output = model(x)
    
    print(f"   ğŸ“¤ è¾“å‡ºç±»å‹: {type(output)}")
    print(f"   ğŸ“¤ è¾“å‡ºé”®: {list(output.keys())}")
    print(f"   ğŸ“¤ 'out' å½¢çŠ¶: {output['out'].shape}")
    print(f"   ğŸ“¤ 'out' æ•°æ®ç±»å‹: {output['out'].dtype}")
    print(f"   ğŸ“¤ åˆ†å‰²å›¾å½¢çŠ¶: (batch, classes, height, width)")
    
    # 7. é¢„å¤„ç†ç¤ºä¾‹
    print("\n7. å®Œæ•´é¢„å¤„ç†ç¤ºä¾‹:")
    
    # æ¨¡æ‹ŸåŸå§‹å›¾åƒ (0-255)
    raw_image = np.random.randint(0, 256, (512, 512, 3), dtype=np.uint8)
    print(f"   ğŸ“· åŸå§‹å›¾åƒ: {raw_image.shape}, èŒƒå›´ [{raw_image.min()}, {raw_image.max()}]")
    
    # è½¬æ¢ä¸ºæµ®ç‚¹æ•°å¹¶å½’ä¸€åŒ–åˆ° [0, 1]
    image_float = raw_image.astype(np.float32) / 255.0
    print(f"   ğŸ”„ å½’ä¸€åŒ–: {image_float.shape}, èŒƒå›´ [{image_float.min():.3f}, {image_float.max():.3f}]")
    
    # ImageNet æ ‡å‡†åŒ–
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image_norm = (image_float - mean) / std
    print(f"   ğŸ“Š æ ‡å‡†åŒ–: {image_norm.shape}, èŒƒå›´ [{image_norm.min():.3f}, {image_norm.max():.3f}]")
    
    # è½¬æ¢ä¸º PyTorch å¼ é‡ (HWC â†’ CHW)
    image_tensor = torch.from_numpy(image_norm.transpose(2, 0, 1)).float()
    print(f"   ğŸ”„ å¼ é‡æ ¼å¼: {image_tensor.shape}, æ•°æ®ç±»å‹: {image_tensor.dtype}")
    
    # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    image_batch = image_tensor.unsqueeze(0)
    print(f"   ğŸ“¦ æ‰¹æ¬¡æ ¼å¼: {image_batch.shape}, æ•°æ®ç±»å‹: {image_batch.dtype}")
    
    # æµ‹è¯•æ¨¡å‹æ¨ç†
    with torch.no_grad():
        result = model(image_batch)
        predictions = torch.argmax(result['out'], dim=1)
        
    print(f"   ğŸ¯ æ¨ç†ç»“æœ: {result['out'].shape}")
    print(f"   ğŸ·ï¸  é¢„æµ‹ç±»åˆ«: {predictions.shape}, å”¯ä¸€å€¼: {torch.unique(predictions).tolist()}")
    
    # 8. å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ
    print("\n8. å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ:")
    print("   âŒ é”™è¯¯: è¾“å…¥ä¸æ˜¯ float ç±»å‹")
    print("      âœ… è§£å†³: image.float() æˆ– image.to(torch.float32)")
    print("   âŒ é”™è¯¯: æ•°æ®ç±»å‹ä¸åŒ¹é… (Double vs Float)")
    print("      âœ… è§£å†³: ä½¿ç”¨ torch.from_numpy(array).float()")
    print("   âŒ é”™è¯¯: è¾“å…¥æ²¡æœ‰æ‰¹æ¬¡ç»´åº¦")
    print("      âœ… è§£å†³: image.unsqueeze(0)")
    print("   âŒ é”™è¯¯: é€šé“é¡ºåºé”™è¯¯ (HWC)")
    print("      âœ… è§£å†³: image.permute(2, 0, 1) æˆ– numpy.transpose(2, 0, 1)")
    print("   âŒ é”™è¯¯: æ²¡æœ‰æ ‡å‡†åŒ–")
    print("      âœ… è§£å†³: ä½¿ç”¨ ImageNet çš„ mean å’Œ std")
    print("   âŒ é”™è¯¯: å€¼åŸŸé”™è¯¯ (0-255)")
    print("      âœ… è§£å†³: å…ˆé™¤ä»¥ 255.0 å†æ ‡å‡†åŒ–")

def create_preprocessing_function():
    """åˆ›å»ºæ ‡å‡†çš„é¢„å¤„ç†å‡½æ•°"""
    
    def preprocess_image(image):
        """
        æ ‡å‡†é¢„å¤„ç†å‡½æ•°
        
        Args:
            image: numpy array, shape (H, W, 3), dtype uint8, range [0, 255]
                  æˆ– PIL Image
        
        Returns:
            torch.Tensor: shape (1, 3, H, W), dtype float32, æ ‡å‡†åŒ–å
        """
        # å¦‚æœæ˜¯ PIL Imageï¼Œè½¬æ¢ä¸º numpy
        if hasattr(image, 'mode'):  # PIL Image
            image = np.array(image)
        
        # ç¡®ä¿æ˜¯ RGB æ ¼å¼
        if len(image.shape) == 3 and image.shape[2] == 3:
            pass  # å·²ç»æ˜¯ RGB
        elif len(image.shape) == 2:
            # ç°åº¦å›¾è½¬ RGB
            image = np.stack([image] * 3, axis=2)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {image.shape}")
        
        # è½¬æ¢ä¸ºæµ®ç‚¹æ•°å¹¶å½’ä¸€åŒ–åˆ° [0, 1]
        if image.dtype == np.uint8:
            image = image.astype(np.float32) / 255.0
        elif image.dtype in [np.float32, np.float64]:
            if image.max() > 1.0:
                image = image / 255.0
        
        # ImageNet æ ‡å‡†åŒ–
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image = (image - mean) / std
        
        # è½¬æ¢ä¸º PyTorch å¼ é‡ (HWC â†’ CHW)
        image_tensor = torch.from_numpy(image.transpose(2, 0, 1)).float()
        
        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
        image_batch = image_tensor.unsqueeze(0)
        
        return image_batch
    
    return preprocess_image

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_lraspp_inputs()
    
    print("\n" + "="*60)
    print("é¢„å¤„ç†å‡½æ•°ç¤ºä¾‹")
    print("="*60)
    
    # åˆ›å»ºé¢„å¤„ç†å‡½æ•°
    preprocess = create_preprocessing_function()
    
    # æµ‹è¯•é¢„å¤„ç†å‡½æ•°
    raw_image = np.random.randint(0, 256, (384, 384, 3), dtype=np.uint8)
    processed = preprocess(raw_image)
    print(f"åŸå§‹å›¾åƒ: {raw_image.shape}, {raw_image.dtype}")
    print(f"å¤„ç†å: {processed.shape}, {processed.dtype}")
    print(f"æ•°å€¼èŒƒå›´: [{processed.min():.3f}, {processed.max():.3f}]")
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
